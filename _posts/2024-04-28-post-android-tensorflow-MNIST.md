---
title:  "[Android] Keras MNIST Androidì— ì ìš© - 1"
search: false
categories: 
  - Android
last_modified_at: 2024-04-28T08:20:00-05:00
comments: true 
---
```yaml
ğŸ“Œ Mac M2 pro ì‚¬ìš©
```
<!--
ë¸”ëŸ­ ì‚¬ìš©ë²•
 ```yaml
```
!-->

<!-- 
[Ruby install](https://rubyinstaller.org/downloads/) í•˜ì´í¼ ë§í¬
![rubyinstaller](/assets/image/Jekll-minimal_mistakes/rubyinstaller.PNG) ì´ë¯¸ì§€
<mark style='background-color: #fff5b1'>...</mark><br> í˜•ê´‘íŒ¬ì²˜ë¦¬
<script src="https://gist.github.com/heui-yong/9f6cd0c69c8780228cbee7c9b324b2f8.js"></script> ì†ŒìŠ¤ì½”ë“œ
--> 

![android-logo](/assets/image/Android/android_logo.png){: style="width: 90%; height:30%;"}

ì˜¤ëŠ˜ì€ ì˜¤ëœë§Œì— ì•ˆë“œë¡œì´ë“œì— ëŒ€í•œ í¬ìŠ¤íŒ…ì„ í•˜ë ¤í•œë‹¤.<br> 
ìš”ì¦˜ íšŒì‚¬ì—ì„œ ë”¥ëŸ¬ë‹ í•™ìŠµì„ ì§„í–‰ì¤‘ì¸ë°, í•™ìŠµí• ë•Œ ì‚¬ìš©í•œ ì†ê¸€ì”¨ ìˆ«ìë¥¼ ì–´ë–¤ ìˆ«ìì¸ì§€ ì¸ì‹í•˜ëŠ” ëª¨ë¸ì„ í…ì„œí”Œë¡œ ë¼ì´íŠ¸ë¥¼ ì‚¬ìš©í•´ì„œ ì•ˆë“œë¡œì´ë“œì— ì ìš©í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì!<br><br>

ë¨¼ì € í…ì„œí”Œë¡œìš°ì™€ ê´€ë ¨ íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì„¤ì¹˜ê°€ ë˜ì–´ìˆë‹¤ëŠ” ê°€ì •í•˜ì— ì§„í–‰í•˜ë‹ˆ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ëŠ” ë‹¤ë¥¸ ë¸”ë¡œê·¸ì˜ í¬ìŠ¤íŒ…ì„ ì°¸ê³ ë¶€íƒë“œë¦½ë‹ˆë‹¤!<br>

<h1>Keras ì†ê¸€ì”¨ ëª¨ë¸ í•™ìŠµí•˜ê¸°</h1>
ì´ë¯¸ ë§ì€ í•™ìŠµëœ ëª¨ë¸ì´ ë§ì§€ë§Œ, ì´ë²ˆ í¬ìŠ¤íŒ…ì˜ ëª©í‘œëŠ” ë‚´ê°€ í•™ìŠµ ì‹œí‚¨ ëª¨ë¸ì„ ì•ˆë“œë¡œì´ë“œì— ì ìš©ì‹œí‚¤ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ëŠ” ê²ƒì´ê¸°ë•Œë¬¸ì— ë¨¼ì € ì§ì ‘ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œë³¼ ê²ƒì´ë‹¤. ë°ì´í„° ì…‹ì˜ ê²½ìš°ëŠ” MNIST ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•  ê²ƒì´ë‹¤. 

<h3>MNIST ë°ì´í„°ì…‹</h3>

```python
from tensorflow.keras.datasets import mnist
import numpy as np

(x_train,y_train),(x_test,y_test) = mnist.load_data()
```

ìœ„ ì½”ë“œë¥¼ ì‚¬ìš©í•´ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤.<br>
ìœ„ë¥¼ í†µí•´ ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ê°€ ì–´ë–¤ ë°ì´í„°ì¸ì§€ ê°„ë‹¨í•˜ê²Œ ì‹œê°í™”í•´ë³´ë©´ ì•„ë˜ì™€ ê°™ë‹¤.<br>

```python
import matplotlib.pyplot as plt
import random
for i in range(1,4,1):
    for j in range(1,4,1):
        plt.subplot(i,4,j)
        plt.imshow(x_train[random.randint(0,60000)],cmap="gray")
    plt.show()
```
![tensorflow-MNIST-1](/assets/image/tensorflow-MNIST/tensorflow-MNIST-1.png){: style="width: 30%; height:30%;"}

<h3>ì…ë ¥ ë°ì´í„° ì •ê·œí™”</h3>
í˜„ì¬ ë§Œë“¤ë ¤ê³ í•˜ëŠ” ëª¨ë¸ì˜ ì…ë ¥ ë°ì´í„°ëŠ” 28, 28 sizeì˜ ì´ë¯¸ì§€ì´ê³ , ê° í”½ì…€ì˜ ê°’ì€ 0~255ì´ë‹¤. ì´ ë°ì´í„°ë¥¼ 0, 1ì˜ ë²”ìœ„ë¡œ ì •ê·œí™”í•  ê²ƒì´ë‹¤. ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ë‹¤. 

```python
from tensorflow.keras.utils import to_categorical

x_train = x_train.reshape(-1,28,28,1)/255.
x_test = x_test.reshape(-1,28,28,1)/255.
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
```
x_trainê³¼ x_testëŠ” Conv2Dë ˆì´ì–´ì— ë„£ê¸° ìœ„í•´ì„œ (28, 28)ì—ì„œ (28, 28, 1)ë¡œ ëª¨ì–‘ì„ ë³€ì¡ì„í•´ì£¼ì—ˆë‹¤.

<h3>model êµ¬ì„±</h3>
ë ˆì´ì–´ë“¤ì„ ìˆœì°¨ì„ìœ¼ë¡œ ìŒ“ì„ ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” kerasì˜ Sequentialëª¨ë¸ì„ ì‚¬ìš©í•œë‹¤.<br>
Dense,Flatten,BatchNormalization,Conv2D ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•œë‹¤. 

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Flatten,BatchNormalization,Conv2D

model = Sequential()
model.add(Conv2D(32,(2,2),activation="relu",input_shape=(28,28,1)))
model.add(BatchNormalization())
model.add(Conv2D(64,(2,2),activation="relu"))
model.add(BatchNormalization())
model.add(Conv2D(128,(2,2),2,activation="relu"))
model.add(BatchNormalization())
model.add(Conv2D(32,(2,2),activation="relu"))
model.add(BatchNormalization())
model.add(Conv2D(64,(2,2),activation="relu"))
model.add(BatchNormalization())
model.add(Conv2D(128,(2,2),2,activation="relu"))
model.add(BatchNormalization())
model.add(Flatten())
model.add(Dense(128,activation="relu"))
model.add(Dense(10,activation="softmax"))
```

<h3>model í•™ìŠµ</h3>

```python
model.compile(loss = "categorical_crossentropy",optimizer = "adam",metrics=["acc"])
history = model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=30,batch_size=256)
```

ë¶„ë¥˜ì‘ì—…ì„ ì§„í–‰í•˜ëŠ” ëª¨ë¸ì´ê¸°ë•Œë¬¸ì— categorical_crossentropyë¡œ ì§€ì •í•´ì£¼ê³  ì˜µí‹°ë§ˆì´ì €ì˜ ê²½ìš°ëŠ” ë§ì´ ì‚¬ìš©í•˜ëŠ” adamì„ ì‚¬ìš©í•´ì£¼ì—ˆë‹¤. ì•„ë˜ë¥¼ í†µí•´ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì.
```python
loss = history.history["loss"]
acc = history.history["acc"]
val_loss = history.history["val_loss"]
val_acc = history.history["val_acc"]
plt.subplot(1,2,1)
plt.plot(range(len(loss)),loss,label = "Train Loss")
plt.plot(range(len(val_loss)),val_loss,label = "Validation Loss")
plt.grid()
plt.legend()
plt.subplot(1,2,2)
plt.plot(range(len(acc)),acc,label = "Train Accuracy")
plt.plot(range(len(val_acc)),val_acc,label = "Validation Accuracy")
plt.grid()
plt.legend()
plt.show()
```

![tensorflow-MNIST-2](/assets/image/tensorflow-MNIST/tensorflow-MNIST-2.png){: style="width: 50%; height:30%;"}

<h3>ê²°ê³¼ í™•ì¸</h3>

```python
index =random.randint(0,9999)
plt.imshow(x_test[index],cmap="gray")
predict = model.predict(x_test[index].reshape(1,28,28,1))
print("Actual : {}\tPredict : {}".format(np.argmax(y_test[index]),np.argmax(predict)),)
```
![tensorflow-MNIST-3](/assets/image/tensorflow-MNIST/tensorflow-MNIST-3.png){: style="width: 50%; height:30%;"}

ê²°ê³¼ë¥¼ í™•ì¸í•˜ë‹ˆ ì˜ ì˜ˆì¸¡í•˜ëŠ”ê±¸ ë³¼ ìˆ˜ ìˆë‹¤. ì´ì œ ëª¨ë¸ì„ ì €ì¥í•´ë³´ì.

<h3>model ì €ì¥</h3>

```python
model.save("tensor_model.h5")
new_model = tf.keras.models.load_model("tensor_model.h5")
convert = tf.lite.TFLiteConverter.from_keras_model(new_model)
tflite_model = convert.convert()
with open('tensor_model.tflite', 'wb') as f:
    f.write(tflite_model)
```

ìœ„ ì½”ë“œë¡œ í•™ìŠµ ì‹œí‚¨ ëª¨ë¸ì„ tensor_model.tfliteë¡œ ì €ì¥í•˜ì˜€ë‹¤.<br>
ì§€ê¸ˆê¹Œì§€ ì•ˆë“œë¡œì´ë“œì— ì ìš©í•  ëª¨ë¸ì˜ ìƒì„±í•˜ëŠ” ë¶€ë¶„ì—ëŒ€í•´ ì•Œì•„ë³´ì•˜ë‹¤. ë‹¤ìŒ í¬ìŠ¤íŒ…ì€ ìƒì„±í•œ ëª¨ë¸ì„ í…ì„œí”Œë¡œ ë¼ì´íŠ¸ë¥¼ ì‚¬ìš©í•´ì„œ ì•ˆë“œë¡œì´ë“œì— ì ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³¼ ê²ƒì´ë‹¤.<br>
ë„ì•..! 